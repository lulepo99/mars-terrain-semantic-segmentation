{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10060667,"sourceType":"datasetVersion","datasetId":6199816},{"sourceId":10122868,"sourceType":"datasetVersion","datasetId":6246507}],"dockerImageVersionId":30804,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Artificial Neural Networks and Deep Learning\n\n---\n\n## Homework 2: Minimal Working Example\n\nTo make your first submission, follow these steps:\n1. Create a folder named `[2024-2025] AN2DL/Homework 2` in your Google Drive.\n2. Upload the `mars_for_students.npz` file to this folder.\n3. Upload the Jupyter notebook `Homework 2 - Minimal Working Example.ipynb`.\n4. Load and process the data.\n5. Implement and train your model.\n6. Submit the generated `.csv` file to Kaggle.","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"s_wjh-H45xdh"}},{"cell_type":"markdown","source":"## ⚙️ Import Libraries","metadata":{"id":"L-uz8SQV5xdk"}},{"cell_type":"code","source":"# Set seed for reproducibility\nseed = 42\n\n# Import necessary libraries\nimport os\n\n# Set environment variables before importing modules\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['PYTHONHASHSEED'] = str(seed)\nos.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n\n# Suppress warnings\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=Warning)\n\n# Import necessary modules\nimport logging\nimport random\nimport numpy as np\nimport imagehash\nfrom IPython.display import FileLink\n\n# Set seeds for random number generators in NumPy and Python\nnp.random.seed(seed)\nrandom.seed(seed)\n\n# Import TensorFlow and Keras\nimport tensorflow as tf\nfrom tensorflow import keras as tfk\nfrom tensorflow.keras import layers as tfkl\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n# Set seed for TensorFlow\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)\n\n# Reduce TensorFlow verbosity\ntf.autograph.set_verbosity(0)\ntf.get_logger().setLevel(logging.ERROR)\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n\n# Import other libraries\nimport os\nimport math\nfrom PIL import Image\nfrom keras import backend as K\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nfrom skimage.util import random_noise\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport matplotlib.patches as mpatches\nimport seaborn as sns\nimport albumentations as A\nfrom albumentations.core.composition import OneOf\nfrom albumentations import Rotate, RandomScale, Compose\nimport cv2\n\n# Configure plot display settings\nsns.set(font_scale=1.4)\nsns.set_style('white')\nplt.rc('font', size=14)\n%matplotlib inline\n\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"Keras version: {tfk.__version__}\")\nprint(f\"GPU devices: {len(tf.config.list_physical_devices('GPU'))}\")","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:07:40.284639Z","iopub.execute_input":"2024-12-13T00:07:40.285549Z","iopub.status.idle":"2024-12-13T00:07:40.302485Z","shell.execute_reply.started":"2024-12-13T00:07:40.285507Z","shell.execute_reply":"2024-12-13T00:07:40.301354Z"},"trusted":true,"id":"qFNOu5Gu5xdl","executionInfo":{"status":"ok","timestamp":1733670052554,"user_tz":-60,"elapsed":303,"user":{"displayName":"Jacopo Libero Tettamanti","userId":"12339511839544746744"}},"outputId":"02659a60-921f-431e-ef01-d432aaefac06"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ⏳ Load the Data","metadata":{"id":"YagofucL5xdm"}},{"cell_type":"code","source":"data = np.load(\"/kaggle/input/data-sets/mars_for_students.npz\")\n\nprint(data.files)\nprint(f\"Training set shape: {data['training_set'].shape}\")\nprint(f\"Test set shape: {data['test_set'].shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:03:48.758946Z","iopub.execute_input":"2024-12-13T00:03:48.759848Z","iopub.status.idle":"2024-12-13T00:03:50.151069Z","shell.execute_reply.started":"2024-12-13T00:03:48.759808Z","shell.execute_reply":"2024-12-13T00:03:50.150096Z"},"trusted":true,"id":"WPR64Wzr5xdm","executionInfo":{"status":"ok","timestamp":1733670511847,"user_tz":-60,"elapsed":3164,"user":{"displayName":"Jacopo Libero Tettamanti","userId":"12339511839544746744"}},"outputId":"7750bb85-04e6-4dd8-ac18-04fb304a5244"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split the files provided. As shown in the previous cell, the test set has\n# no labels\ntraining_set = data[\"training_set\"]\nX_data = training_set[:, 0]\ny_data = training_set[:, 1]\n\nX_test = data[\"test_set\"]\n\nprint(f\"Training X shape: {X_data.shape}\")\nprint(f\"Training y shape: {y_data.shape}\")\nprint(f\"Test X shape: {X_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:03:55.227465Z","iopub.execute_input":"2024-12-13T00:03:55.228127Z","iopub.status.idle":"2024-12-13T00:03:56.564454Z","shell.execute_reply.started":"2024-12-13T00:03:55.228092Z","shell.execute_reply":"2024-12-13T00:03:56.563573Z"},"trusted":true,"id":"dR4K--9v5xdn","outputId":"61c46f7f-58ba-4f2d-c75d-8a4213bda83a","executionInfo":{"status":"ok","timestamp":1733670518461,"user_tz":-60,"elapsed":2530,"user":{"displayName":"Jacopo Libero Tettamanti","userId":"12339511839544746744"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verify the minimum and maximum values in X_data and X_test\nprint(\"Original data range:\")\nprint(f\"X_data: Min = {X_data.min()}, Max = {X_data.max()}\")\nprint(f\"X_test: Min = {X_test.min()}, Max = {X_test.max()}\")","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:04:02.610923Z","iopub.execute_input":"2024-12-13T00:04:02.611268Z","iopub.status.idle":"2024-12-13T00:04:02.661586Z","shell.execute_reply.started":"2024-12-13T00:04:02.611240Z","shell.execute_reply":"2024-12-13T00:04:02.660849Z"},"trusted":true,"id":"_5qif7jd5xdn","outputId":"83f0c742-fd1c-4297-dc88-265fe32e9b0a","executionInfo":{"status":"ok","timestamp":1733670522149,"user_tz":-60,"elapsed":190,"user":{"displayName":"Jacopo Libero Tettamanti","userId":"12339511839544746744"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_shape = (64, 128, 1)\noutput_shape = len(np.unique(y_data))\n\nprint(f\"Output shape: {output_shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:04:07.004147Z","iopub.execute_input":"2024-12-13T00:04:07.005026Z","iopub.status.idle":"2024-12-13T00:04:07.599618Z","shell.execute_reply.started":"2024-12-13T00:04:07.004991Z","shell.execute_reply":"2024-12-13T00:04:07.598728Z"},"trusted":true,"id":"5uQToB625xdn","outputId":"55f210e1-c10c-433e-c9b7-81456a174b87","executionInfo":{"status":"ok","timestamp":1733670526987,"user_tz":-60,"elapsed":1205,"user":{"displayName":"Jacopo Libero Tettamanti","userId":"12339511839544746744"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Count the number of pixels for each class\nclass_counts = np.zeros(output_shape, dtype=int)\nfor mask in y_data:\n    class_counts += np.bincount(mask.flatten().astype(int), minlength=output_shape)\n\n# Calculate the proportion of pixels for each class\ntotal_pixels = class_counts.sum()\nclass_distribution = class_counts / total_pixels\n\n# Print the results in a formatted way\nprint(\"Number of pixels and percentage distribution per class:\")\nfor class_index, (count, percentage) in enumerate(zip(class_counts, class_distribution * 100)):\n    print(f\"Class {class_index}: {count} pixels ({percentage:.2f}%)\")\n\n# Plot the distribution\nclass_labels = [f\"Class {i}\" for i in range(output_shape)]\n\nplt.figure(figsize=(5, 4))\nplt.bar(class_labels, class_distribution * 100)\nplt.xlabel(\"Classes\", fontsize=10)\nplt.ylabel(\"Pixel percentage\", fontsize=10)\nplt.title(\"Class Distribution in Training set\", fontsize=12)\nplt.xticks(fontsize=9)\nplt.yticks(fontsize=9)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:04:16.084152Z","iopub.execute_input":"2024-12-13T00:04:16.084906Z","iopub.status.idle":"2024-12-13T00:04:16.363594Z","shell.execute_reply.started":"2024-12-13T00:04:16.084869Z","shell.execute_reply":"2024-12-13T00:04:16.362423Z"},"trusted":true,"id":"o-ROrR4H5xdn","outputId":"a46bbeec-1172-4b27-8670-59c275c1b145","executionInfo":{"status":"ok","timestamp":1733670533464,"user_tz":-60,"elapsed":985,"user":{"displayName":"Jacopo Libero Tettamanti","userId":"12339511839544746744"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate histograms\nbins = np.linspace(0, 255, 50)  # Define 50 bins between 0 and 255\ntrain_hist, _ = np.histogram(X_data.flatten(), bins=bins)\ntest_hist, _ = np.histogram(X_test.flatten(), bins=bins)\n\n# Create two subplots side by side\nfig, axs = plt.subplots(1, 2, figsize=(12, 5), sharey=True)  # Same y-axis for easier comparison\n\n# Training histogram\naxs[0].hist(X_data.flatten(), bins=bins, color='blue', alpha=0.7, label=\"Training\")\naxs[0].set_title(\"Training Pixel Distribution\")\naxs[0].set_xlabel(\"Pixel Intensity\")\naxs[0].set_ylabel(\"Count\")\naxs[0].legend()\n\n# Test histogram\naxs[1].hist(X_test.flatten(), bins=bins, color='orange', alpha=0.7, label=\"Test\")\naxs[1].set_title(\"Test Pixel Distribution\")\naxs[1].set_xlabel(\"Pixel Intensity\")\naxs[1].legend()\n\n# Adjust layout and show plot\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:04:29.775065Z","iopub.execute_input":"2024-12-13T00:04:29.775895Z","iopub.status.idle":"2024-12-13T00:04:36.003343Z","shell.execute_reply.started":"2024-12-13T00:04:29.775857Z","shell.execute_reply":"2024-12-13T00:04:36.002469Z"},"trusted":true,"id":"AQcEwWJX5xdo","outputId":"16d16311-be75-4ebc-efe6-f91dedc12266","executionInfo":{"status":"ok","timestamp":1733670549090,"user_tz":-60,"elapsed":10479,"user":{"displayName":"Jacopo Libero Tettamanti","userId":"12339511839544746744"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dictionary for the classes names\nclass_names = {\n    0: \"Background\",\n    1: \"Soil\",\n    2: \"Bedrock\",\n    3: \"Sand\",\n    4: \"Big Rock\"\n}","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:04:41.485127Z","iopub.execute_input":"2024-12-13T00:04:41.485888Z","iopub.status.idle":"2024-12-13T00:04:41.490096Z","shell.execute_reply.started":"2024-12-13T00:04:41.485847Z","shell.execute_reply":"2024-12-13T00:04:41.489124Z"},"trusted":true,"id":"xEPQo3Yv5xdo"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def display_random_samples(images, masks=None, class_names=None, num_samples=None, fontsize=None):\n    # Define figure size and grid layout. Two columns if masks exist, otherwise one\n    cols = 3 if masks is not None else 1  # Aggiungi una colonna extra per la legenda\n    fig = plt.figure(figsize=(12, num_samples * 4))  # Modifica la dimensione del grafico\n    gs = gridspec.GridSpec(num_samples, cols, hspace=0.3, wspace=0.4)\n\n    for i in range(num_samples):\n        # Select a random index\n        idx = random.randint(0, len(images) - 1)\n\n        # Plot the image\n        ax1 = fig.add_subplot(gs[i, 0])\n        ax1.imshow(images[idx].squeeze(), cmap='gray')\n        ax1.set_title(f\"Image {idx}\", fontsize=fontsize)\n        ax1.axis('off')\n\n        if masks is not None:\n            # Plot the corresponding mask\n            ax2 = fig.add_subplot(gs[i, 1])\n            mask = masks[idx].squeeze()\n\n            # Ensure mask values are integers corresponding to class indices\n            mask = mask.astype(int)\n\n            # Plot the mask with a proper colormap\n            num_classes = len(class_names)\n            colormap = plt.cm.get_cmap(\"viridis\", num_classes)\n            ax2.imshow(mask, cmap=colormap, vmin=0, vmax=num_classes - 1)\n            ax2.set_title(f\"Mask {idx}\", fontsize=fontsize)\n            ax2.axis('off')\n\n            # Add legend in a separate subplot\n            ax3 = fig.add_subplot(gs[i, 2])\n            ax3.axis('off')  # Rimuove gli assi per la legenda\n\n            # Create legend elements\n            legend_elements = [\n                mpatches.Patch(color=colormap(c / (num_classes - 1)), label=class_names[c])\n                for c in range(num_classes)\n            ]\n\n            # Add the legend to the figure\n            ax3.legend(\n                handles=legend_elements,\n                loc=\"center\",\n                fontsize=fontsize,\n                frameon=False\n            )\n\n    plt.tight_layout(pad=0.5)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:04:46.391422Z","iopub.execute_input":"2024-12-13T00:04:46.392282Z","iopub.status.idle":"2024-12-13T00:04:46.401078Z","shell.execute_reply.started":"2024-12-13T00:04:46.392245Z","shell.execute_reply":"2024-12-13T00:04:46.400294Z"},"trusted":true,"id":"uNj5821M5xdo"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize 5 random samples\ndisplay_random_samples(X_data, masks=y_data, class_names=class_names, num_samples=5, fontsize=8)","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:04:55.578868Z","iopub.execute_input":"2024-12-13T00:04:55.579198Z","iopub.status.idle":"2024-12-13T00:04:57.283091Z","shell.execute_reply.started":"2024-12-13T00:04:55.579170Z","shell.execute_reply":"2024-12-13T00:04:57.282246Z"},"trusted":true,"id":"vOl3H0ql5xdp","outputId":"ff212498-3c37-47ea-fb68-fe7780e7a28e","executionInfo":{"status":"ok","timestamp":1733670560365,"user_tz":-60,"elapsed":3580,"user":{"displayName":"Jacopo Libero Tettamanti","userId":"12339511839544746744"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize 5 random samples from the test set (without masks)\ndisplay_random_samples(X_test, num_samples=5, fontsize=8)","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:05:03.868707Z","iopub.execute_input":"2024-12-13T00:05:03.869370Z","iopub.status.idle":"2024-12-13T00:05:04.567473Z","shell.execute_reply.started":"2024-12-13T00:05:03.869333Z","shell.execute_reply":"2024-12-13T00:05:04.566557Z"},"trusted":true,"id":"3njS5xLT5xdp","outputId":"fe5ff14c-cccc-46ec-8944-155130ddb117","executionInfo":{"status":"ok","timestamp":1733670571905,"user_tz":-60,"elapsed":1357,"user":{"displayName":"Jacopo Libero Tettamanti","userId":"12339511839544746744"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Indices of the images and masks to inspect\nsample_indices = [1370, 2161]\n\n# Set up the plot for multiple images and masks\nplt.figure(figsize=(10, len(sample_indices) * 5))  # Adjust the height based on the number of samples\n\nfor i, sample_index in enumerate(sample_indices):\n    # Display the image\n    plt.subplot(len(sample_indices), 2, i * 2 + 1)\n    plt.imshow(X_data[sample_index].squeeze(), cmap='gray')  # cmap='gray' for grayscale images\n    plt.title(f\"Image {sample_index} (X_data)\")\n    plt.axis('off')\n\n    # Display the mask\n    plt.subplot(len(sample_indices), 2, i * 2 + 2)\n    plt.imshow(y_data[sample_index].squeeze(), cmap='viridis')  # cmap='viridis' for masks\n    plt.title(f\"Mask {sample_index} (y_data)\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:05:13.485402Z","iopub.execute_input":"2024-12-13T00:05:13.485985Z","iopub.status.idle":"2024-12-13T00:05:14.141435Z","shell.execute_reply.started":"2024-12-13T00:05:13.485942Z","shell.execute_reply":"2024-12-13T00:05:14.140594Z"},"trusted":true,"id":"ZBK3ccKc5xdp","outputId":"cfe42237-a354-43d7-f933-9170397680c0","executionInfo":{"status":"ok","timestamp":1733670576652,"user_tz":-60,"elapsed":1169,"user":{"displayName":"Jacopo Libero Tettamanti","userId":"12339511839544746744"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Alien image mask used as a reference\nmask_reference = y_data[1370]\nmask_tuple = tuple(mask_reference.flatten())\n\n# Find all the duplicate images\nduplicate_indices = [\n    idx for idx, mask in enumerate(y_data)\n    if tuple(mask.flatten()) == mask_tuple\n]\n\nprint(f\"Found {len(duplicate_indices)} images with identical masks to the reference.\")\n\n# Filter the dataset deleting the duplicate images\noriginal_size = len(y_data)\nremaining_indices = [idx for idx in range(len(y_data)) if idx not in duplicate_indices]\nX_data = X_data[remaining_indices]\ny_data = y_data[remaining_indices]\n\n\nprint(f\"Original dataset size: {original_size}\")\nprint(f\"Filtered dataset size: {len(y_data)}\")\nprint(f\"Number of removed images: {len(duplicate_indices)}\")","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:05:20.941451Z","iopub.execute_input":"2024-12-13T00:05:20.941806Z","iopub.status.idle":"2024-12-13T00:05:21.889018Z","shell.execute_reply.started":"2024-12-13T00:05:20.941774Z","shell.execute_reply":"2024-12-13T00:05:21.888028Z"},"trusted":true,"id":"6Yk5a2hi5xdp","outputId":"75044b6d-15d5-456a-988e-b35d0c367f19","executionInfo":{"status":"ok","timestamp":1733670592072,"user_tz":-60,"elapsed":1459,"user":{"displayName":"Jacopo Libero Tettamanti","userId":"12339511839544746744"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate the class distribution for each mask\nclass_profiles_data = np.array([\n    np.bincount(mask.flatten().astype(int), minlength=output_shape) / mask.size\n    for mask in y_data\n])\n\n# Perform a split in train_val and test while respecting the distribution\nX_train_val, X_our_test, y_train_val, y_our_test = train_test_split(\n    X_data, y_data,\n    test_size=0.2,\n    random_state=seed,\n    stratify=class_profiles_data.argmax(axis=1)\n)\n\n# Compute again the class distribution for each mask\nclass_profiles_train_val = np.array([\n    np.bincount(mask.flatten().astype(int), minlength=output_shape) / mask.size\n    for mask in y_train_val\n])\n\n# Perform a split in train and validation while respecting the distribution\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train_val, y_train_val,\n    test_size=0.25,  # 25% is equal to the 20% of total\n    random_state=seed,\n    stratify=class_profiles_train_val.argmax(axis=1)\n)\n\n# Controlla la distribuzione\nprint(f\"Training set: {len(X_train)} samples\")\nprint(f\"Validation set: {len(X_val)} samples\")\nprint(f\"Test set: {len(X_our_test)} samples\")","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:05:32.293718Z","iopub.execute_input":"2024-12-13T00:05:32.294115Z","iopub.status.idle":"2024-12-13T00:05:32.636396Z","shell.execute_reply.started":"2024-12-13T00:05:32.294083Z","shell.execute_reply":"2024-12-13T00:05:32.635514Z"},"trusted":true,"id":"JuYxiGjJ5xdq","outputId":"270d7a87-9d0f-464c-ea92-cfde1057c6f0","executionInfo":{"status":"ok","timestamp":1733670691792,"user_tz":-60,"elapsed":564,"user":{"displayName":"Jacopo Libero Tettamanti","userId":"12339511839544746744"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to compute and display class distribution\ndef compute_class_distribution(y, output_shape):\n    # Flatten the labels to predominant classes per mask\n    y_flat = np.array([np.argmax(np.bincount(mask.flatten().astype(int), minlength=output_shape)) for mask in y])\n\n    # Count the number of masks for each class\n    predominant_classes, class_counts = np.unique(y_flat, return_counts=True)\n\n    # Create a dictionary to include all classes, even those with zero counts\n    class_distribution = {class_label: 0 for class_label in range(output_shape)}\n    for label, count in zip(predominant_classes, class_counts):\n        class_distribution[label] = count\n\n    return class_distribution\n\n# Compute class distribution for training, validation, and test sets\ntrain_distribution = compute_class_distribution(y_train, output_shape)\nval_distribution = compute_class_distribution(y_val, output_shape)\ntest_distribution = compute_class_distribution(y_our_test, output_shape)\n\n# Prepare data for visualization\nlabels = [f\"Class {i}\" for i in range(output_shape)]\ntrain_counts = [train_distribution[i] for i in range(output_shape)]\nval_counts = [val_distribution[i] for i in range(output_shape)]\ntest_counts = [test_distribution[i] for i in range(output_shape)]\n\n# Plot the distributions\nx = np.arange(output_shape)  # Class indices\n\nplt.figure(figsize=(10, 6))\nplt.bar(x - 0.2, train_counts, width=0.2, label='Training', color='darkblue')\nplt.bar(x, val_counts, width=0.2, label='Validation', color='orange')\nplt.bar(x + 0.2, test_counts, width=0.2, label='Test', color='green')\nplt.xticks(x, labels, fontsize=10)\nplt.xlabel(\"Classes\", fontsize=12)\nplt.ylabel(\"Number of Masks\", fontsize=12)\nplt.title(\"Class Distribution in Training, Validation, and Test Sets\", fontsize=14)\nplt.legend(fontsize=10)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:05:39.926207Z","iopub.execute_input":"2024-12-13T00:05:39.926564Z","iopub.status.idle":"2024-12-13T00:05:40.336738Z","shell.execute_reply.started":"2024-12-13T00:05:39.926536Z","shell.execute_reply":"2024-12-13T00:05:40.335828Z"},"trusted":true,"id":"DUXzXyAU5xdq","outputId":"aea970f6-5ecc-4a8b-d738-6e1caa61a66f","executionInfo":{"status":"ok","timestamp":1733670985976,"user_tz":-60,"elapsed":866,"user":{"displayName":"Jacopo Libero Tettamanti","userId":"12339511839544746744"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# The following functions are needed to transfer class 4 portions from image with class 4 pixels\n# images that do not have them\n\ndef extract_class_4_portion(image, mask, target_class=4, crop_size=(16, 16)):\n    # Find the indices of all pixels belonging to the target class\n    indices = np.argwhere(mask == target_class)\n    if len(indices) == 0:\n        return None, None  # No portion of the target class found\n    \n    # Select a random center pixel from the target class\n    center = random.choice(indices)\n    y, x = center\n    \n    # Calculate the cropping boundaries\n    crop_y1 = max(0, y - crop_size[0] // 2)\n    crop_y2 = min(mask.shape[0], y + crop_size[0] // 2)\n    crop_x1 = max(0, x - crop_size[1] // 2)\n    crop_x2 = min(mask.shape[1], x + crop_size[1] // 2)\n    \n    # Crop the image and mask around the center pixel\n    cropped_image = image[crop_y1:crop_y2, crop_x1:crop_x2]\n    cropped_mask = mask[crop_y1:crop_y2, crop_x1:crop_x2]\n    \n    return cropped_image, cropped_mask\n\ndef apply_transfer(image, mask, class_4_portion, class_4_mask):\n    # Get the dimensions of the portion to transfer\n    h, w = class_4_portion.shape[:2]\n    max_y, max_x = image.shape[:2]\n    \n    # Randomly select the position to paste the portion\n    paste_y = random.randint(0, max_y - h)\n    paste_x = random.randint(0, max_x - w)\n\n    # Create copies of the original image and mask\n    new_image = image.copy()\n    new_mask = mask.copy()\n    \n    # Paste the portion and mask onto the new image and mask\n    new_image[paste_y:paste_y + h, paste_x:paste_x + w] = class_4_portion\n    new_mask[paste_y:paste_y + h, paste_x:paste_x + w] = class_4_mask\n    \n    return new_image, new_mask\n\n# Define a transformation pipeline with rotation and scaling\ntransform = Compose([\n    Rotate(limit=15, p=0.5),  # Randomly rotate within ±15 degrees\n    RandomScale(scale_limit=0.1, p=0.5),  # Randomly scale by ±10%\n])\n\n# Percentage of images without class 4 to modify\ntransfer_percentage = 0.8\nnum_images = len(X_train)\nnum_to_transfer = int(transfer_percentage * num_images)\n\n# Find indices of images without class 4 in their masks\nindices_without_class_4 = [i for i, mask in enumerate(y_train) if 4 not in np.unique(mask)]\n\n# Randomly select a subset of these images to modify\nindices_to_modify = random.sample(indices_without_class_4, num_to_transfer)\n\n# Initialize lists to store transformed images and masks\ntransformed_X_train = []\ntransformed_y_train = []\n\nfor i, (image, mask) in enumerate(zip(X_train, y_train)):\n    if i in indices_to_modify:\n        # Select a random image that contains class 4\n        class_4_index = random.choice([j for j, m in enumerate(y_train) if 4 in np.unique(m)])\n        class_4_image = X_train[class_4_index]\n        class_4_mask = y_train[class_4_index]\n        \n        # Extract a random portion of class 4 from the selected image\n        portion, portion_mask = extract_class_4_portion(class_4_image, class_4_mask, target_class=4)\n        if portion is not None:\n            # Apply light transformations to the extracted portion\n            transformed = transform(image=portion, mask=portion_mask)\n            portion_transformed = transformed['image']\n            mask_transformed = transformed['mask']\n            \n            # Overlay the transformed portion onto the current image\n            new_image, new_mask = apply_transfer(image, mask, portion_transformed, mask_transformed)\n            transformed_X_train.append(new_image)\n            transformed_y_train.append(new_mask)\n        else:\n            # If no portion could be extracted, add the original image and mask\n            transformed_X_train.append(image)\n            transformed_y_train.append(mask)\n    else:\n        # Add unmodified images and masks to the dataset\n        transformed_X_train.append(image)\n        transformed_y_train.append(mask)\n\n# Convert the transformed data back to NumPy arrays\nX_train_new = np.array(transformed_X_train)\ny_train_new = np.array(transformed_y_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T00:18:55.774224Z","iopub.execute_input":"2024-12-13T00:18:55.774948Z","iopub.status.idle":"2024-12-13T00:20:52.300558Z","shell.execute_reply.started":"2024-12-13T00:18:55.774909Z","shell.execute_reply":"2024-12-13T00:20:52.299712Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize 5 random samples\ndisplay_random_samples(X_train_new, masks=y_train_new, class_names=class_names, num_samples=5, fontsize=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T00:21:04.841371Z","iopub.execute_input":"2024-12-13T00:21:04.841739Z","iopub.status.idle":"2024-12-13T00:21:06.554712Z","shell.execute_reply.started":"2024-12-13T00:21:04.841707Z","shell.execute_reply":"2024-12-13T00:21:06.553793Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Count the number of pixels for each class\nclass_counts = np.zeros(output_shape, dtype=int)\nfor mask in y_train_new:\n    class_counts += np.bincount(mask.flatten().astype(int), minlength=output_shape)\n\n# Calculate the proportion of pixels for each class\ntotal_pixels = class_counts.sum()\nclass_distribution = class_counts / total_pixels\n\n# Print the results in a formatted way\nprint(\"Number of pixels and percentage distribution per class:\")\nfor class_index, (count, percentage) in enumerate(zip(class_counts, class_distribution * 100)):\n    print(f\"Class {class_index}: {count} pixels ({percentage:.2f}%)\")\n\n# Plot the distribution\nclass_labels = [f\"Class {i}\" for i in range(output_shape)]\n\nplt.figure(figsize=(5, 4))\nplt.bar(class_labels, class_distribution * 100)\nplt.xlabel(\"Classes\", fontsize=10)\nplt.ylabel(\"Pixel percentage\", fontsize=10)\nplt.title(\"Class Distribution in Training set\", fontsize=12)\nplt.xticks(fontsize=9)\nplt.yticks(fontsize=9)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T00:21:20.365562Z","iopub.execute_input":"2024-12-13T00:21:20.366327Z","iopub.status.idle":"2024-12-13T00:21:20.592174Z","shell.execute_reply.started":"2024-12-13T00:21:20.366292Z","shell.execute_reply":"2024-12-13T00:21:20.591255Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# General transformations\ngeneral_augmentations = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.Rotate(limit=30, p=0.5),\n    \n    A.ElasticTransform(alpha=1, sigma=10, alpha_affine=10, p=0.5), \n    \n], p=1,additional_targets={'mask': 'mask'})\n\n# Transformations for class 4\nfocused_augmentations = A.Compose([\n    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=10, p=0.5),\n    A.RandomScale(scale_limit=0.2, p=0.5), \n    A.ElasticTransform(alpha=2, sigma=20, alpha_affine=20, p=0.5),\n    A.CropNonEmptyMaskIfExists(height=48, width=96, p=0.5),\n], p=1,additional_targets={'mask': 'mask'})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T00:21:29.666367Z","iopub.execute_input":"2024-12-13T00:21:29.667288Z","iopub.status.idle":"2024-12-13T00:21:29.678749Z","shell.execute_reply.started":"2024-12-13T00:21:29.667250Z","shell.execute_reply":"2024-12-13T00:21:29.677761Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Zoom for images with class 4\n\ndef zoom_on_class_4(image, mask, zoom_factor=1.1, seed=None):\n    np.random.seed(seed)  \n    height, width = mask.shape\n\n    class_4_pixels = np.argwhere(mask == 4)\n\n    # return the original images and mask if class 4 pixels are not present\n    if class_4_pixels.size == 0:\n        return image, mask\n\n    # Compute bounding box around class 4 pixels\n    top_left = class_4_pixels.min(axis=0)\n    bottom_right = class_4_pixels.max(axis=0)\n\n    top, left = top_left\n    bottom, right = bottom_right\n\n    # Add margin to the bounding box based on the zoom factor\n    margin_h = int((bottom - top) * (zoom_factor - 1) / 2)\n    margin_w = int((right - left) * (zoom_factor - 1) / 2)\n\n    # Limit the coordinates to stay within the image boundaries\n    top = max(0, top - margin_h)\n    bottom = min(height, bottom + margin_h)\n    left = max(0, left - margin_w)\n    right = min(width, right + margin_w)\n\n    # Perform the crop operation\n    cropped_image = image[top:bottom, left:right]\n    cropped_mask = mask[top:bottom, left:right]\n\n    # Safety check: if the crop is empty, return the original image and mask\n    if cropped_image.size == 0 or cropped_mask.size == 0:\n        return image, mask\n\n    # Resize the cropped region to match the original dimensions\n    zoomed_image = cv2.resize(cropped_image, (width, height), interpolation=cv2.INTER_LINEAR)\n    zoomed_mask = cv2.resize(cropped_mask, (width, height), interpolation=cv2.INTER_NEAREST)\n\n    return zoomed_image, zoomed_mask\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T00:21:35.704611Z","iopub.execute_input":"2024-12-13T00:21:35.705018Z","iopub.status.idle":"2024-12-13T00:21:35.713167Z","shell.execute_reply.started":"2024-12-13T00:21:35.704978Z","shell.execute_reply":"2024-12-13T00:21:35.712141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Oversampling\naugmented_X_train = []\naugmented_y_train = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T00:21:42.044152Z","iopub.execute_input":"2024-12-13T00:21:42.044515Z","iopub.status.idle":"2024-12-13T00:21:42.049389Z","shell.execute_reply.started":"2024-12-13T00:21:42.044483Z","shell.execute_reply":"2024-12-13T00:21:42.048273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loop over the augmented data\nfor image, mask in zip(X_train_new, y_train_new):\n    # General transformation\n    for _ in range(2): \n        augmented = general_augmentations(image=image, mask=mask)\n        \n        # Ridimensiona per garantire uniformità\n        augmented_image = cv2.resize(augmented['image'], (128, 64))\n        augmented_mask = cv2.resize(augmented['mask'], (128, 64), interpolation=cv2.INTER_NEAREST)\n        \n        augmented_X_train.append(augmented_image)\n        augmented_y_train.append(augmented_mask)\n\n    # Transformations for image with class 4\n    if 4 in np.unique(mask):\n        zoomed_image, zoomed_mask = zoom_on_class_4(image, mask, zoom_factor=9.5)\n\n        for _ in range(4): \n            augmented = focused_augmentations(image=zoomed_image, mask=zoomed_mask)\n            \n            augmented_image = cv2.resize(augmented['image'], (128, 64))\n            augmented_mask = cv2.resize(augmented['mask'], (128, 64), interpolation=cv2.INTER_NEAREST)\n            \n            augmented_X_train.append(augmented_image)\n            augmented_y_train.append(augmented_mask)\n\naugmented_X_train = np.array(augmented_X_train)\naugmented_y_train = np.array(augmented_y_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T00:21:48.283048Z","iopub.execute_input":"2024-12-13T00:21:48.283526Z","iopub.status.idle":"2024-12-13T00:21:56.323230Z","shell.execute_reply.started":"2024-12-13T00:21:48.283481Z","shell.execute_reply":"2024-12-13T00:21:56.322448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Count the number of pixels for each class\nclass_counts = np.zeros(output_shape, dtype=int)\nfor mask in augmented_y_train:\n    class_counts += np.bincount(mask.flatten().astype(int), minlength=output_shape)\n\n# Calculate the proportion of pixels for each class\ntotal_pixels = class_counts.sum()\nclass_distribution = class_counts / total_pixels\n\n# Print the results in a formatted way\nprint(\"Number of pixels and percentage distribution per class:\")\nfor class_index, (count, percentage) in enumerate(zip(class_counts, class_distribution * 100)):\n    print(f\"Class {class_index}: {count} pixels ({percentage:.2f}%)\")\n\n# Plot the distribution\nclass_labels = [f\"Class {i}\" for i in range(output_shape)]\n\nplt.figure(figsize=(5, 4))\nplt.bar(class_labels, class_distribution * 100)\nplt.xlabel(\"Classes\", fontsize=10)\nplt.ylabel(\"Pixel percentage\", fontsize=10)\nplt.title(\"Class Distribution in Training set\", fontsize=12)\nplt.xticks(fontsize=9)\nplt.yticks(fontsize=9)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T00:22:14.062953Z","iopub.execute_input":"2024-12-13T00:22:14.063306Z","iopub.status.idle":"2024-12-13T00:22:14.630129Z","shell.execute_reply.started":"2024-12-13T00:22:14.063279Z","shell.execute_reply":"2024-12-13T00:22:14.629259Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Combine original and augmented data\nX_train_new2 = np.concatenate([X_train_new, augmented_X_train])\ny_train_new2 = np.concatenate([y_train_new, augmented_y_train])\n\n# Debug: Print statistics\nprint(f\"Original training set size: {len(X_train)}\")\nprint(f\"Augmented training set size: {len(augmented_X_train)}\")\nprint(f\"Final training set size: {len(X_train_new2)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:22:33.019556Z","iopub.execute_input":"2024-12-13T00:22:33.020267Z","iopub.status.idle":"2024-12-13T00:22:33.443278Z","shell.execute_reply.started":"2024-12-13T00:22:33.020227Z","shell.execute_reply":"2024-12-13T00:22:33.442415Z"},"trusted":true,"id":"seLBVFFP5xdr","outputId":"38828850-92f3-4175-ba8a-05b8a9135e4b","executionInfo":{"status":"ok","timestamp":1733671017881,"user_tz":-60,"elapsed":468,"user":{"displayName":"Jacopo Libero Tettamanti","userId":"12339511839544746744"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Count the number of pixels for each class\nclass_counts = np.zeros(output_shape, dtype=int)\nfor mask in y_train_new2:\n    class_counts += np.bincount(mask.flatten().astype(int), minlength=output_shape)\n\n# Calculate the proportion of pixels for each class\ntotal_pixels = class_counts.sum()\nclass_distribution = class_counts / total_pixels\n\n# Print the results in a formatted way\nprint(\"Number of pixels and percentage distribution per class:\")\nfor class_index, (count, percentage) in enumerate(zip(class_counts, class_distribution * 100)):\n    print(f\"Class {class_index}: {count} pixels ({percentage:.2f}%)\")\n\n# Plot the distribution\nclass_labels = [f\"Class {i}\" for i in range(output_shape)]\n\nplt.figure(figsize=(5, 4))\nplt.bar(class_labels, class_distribution * 100)\nplt.xlabel(\"Classes\", fontsize=10)\nplt.ylabel(\"Pixel percentage\", fontsize=10)\nplt.title(\"Class Distribution in Training set\", fontsize=12)\nplt.xticks(fontsize=9)\nplt.yticks(fontsize=9)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T00:22:46.559106Z","iopub.execute_input":"2024-12-13T00:22:46.559432Z","iopub.status.idle":"2024-12-13T00:22:47.037894Z","shell.execute_reply.started":"2024-12-13T00:22:46.559405Z","shell.execute_reply":"2024-12-13T00:22:47.036851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize 5 random samples\ndisplay_random_samples(augmented_X_train, masks=augmented_y_train, class_names=class_names, num_samples=5, fontsize=8)","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:24:35.777589Z","iopub.execute_input":"2024-12-13T00:24:35.778699Z","iopub.status.idle":"2024-12-13T00:24:37.270197Z","shell.execute_reply.started":"2024-12-13T00:24:35.778661Z","shell.execute_reply":"2024-12-13T00:24:37.269306Z"},"trusted":true,"id":"AmC3BH7s5xdr","outputId":"6b254a70-71d5-4065-e2f3-114bfeffde13","executionInfo":{"status":"ok","timestamp":1733671026699,"user_tz":-60,"elapsed":2863,"user":{"displayName":"Jacopo Libero Tettamanti","userId":"12339511839544746744"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_min = X_train_new2.min()\ntrain_max = X_train_new2.max()\n\nval_min = X_val.min()\nval_max = X_val.max()\n\ntest_min = X_test.min()\ntest_max = X_test.max()\n\nour_test_min = X_our_test.min()\nour_test_max = X_our_test.max()\n\n# Add color channel and rescale pixels between 0 and 1\nX_train_new2 = (X_train_new2 - train_min) / (train_max - train_min)\nX_train_new2 = X_train_new2[..., np.newaxis]\n\nX_val = (X_val - val_min) / (val_max - val_min)\nX_val = X_val[..., np.newaxis]\n\nX_our_test = (X_our_test - our_test_min) / (our_test_max - our_test_min)\nX_our_test = X_our_test[..., np.newaxis]\n\nX_test = (X_test - test_min) / (test_max - test_min)\nX_test = X_test[..., np.newaxis]\n\n\ninput_shape = X_train.shape[1:]\nnum_classes = len(np.unique(y_data))\n\nprint(f\"Input shape: {input_shape}\")\nprint(f\"Number of classes: {num_classes}\")","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:24:47.359159Z","iopub.execute_input":"2024-12-13T00:24:47.360045Z","iopub.status.idle":"2024-12-13T00:24:48.934286Z","shell.execute_reply.started":"2024-12-13T00:24:47.360012Z","shell.execute_reply":"2024-12-13T00:24:48.933331Z"},"trusted":true,"id":"FDAWPc3V5xdr","outputId":"d45c02b1-b0c5-4a7f-ffe7-097b3b320336","executionInfo":{"status":"ok","timestamp":1733671031462,"user_tz":-60,"elapsed":1525,"user":{"displayName":"Jacopo Libero Tettamanti","userId":"12339511839544746744"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print shapes\nprint(f\"X_train shape: {X_train_new2.shape}\")\nprint(f\"y_train shape: {y_train_new2.shape}\")\nprint(f\"X_val shape: {X_val.shape}\")\nprint(f\"y_val shape: {y_val.shape}\")\nprint(f\"X_our_test shape: {X_our_test.shape}\")\nprint(f\"y_our_test shape: {y_our_test.shape}\")\nprint(f\"X_test shape: {X_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:24:54.809793Z","iopub.execute_input":"2024-12-13T00:24:54.810169Z","iopub.status.idle":"2024-12-13T00:24:54.815541Z","shell.execute_reply.started":"2024-12-13T00:24:54.810138Z","shell.execute_reply":"2024-12-13T00:24:54.814582Z"},"trusted":true,"id":"X4IW059s5xdr","outputId":"a69d05a7-f97b-42e6-fd15-e5aac6c8dfad","executionInfo":{"status":"ok","timestamp":1733671032955,"user_tz":-60,"elapsed":221,"user":{"displayName":"Jacopo Libero Tettamanti","userId":"12339511839544746744"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Training set: Min = {X_train_new2.min()}, Max = {X_train_new2.max()}\")\nprint(f\"Validation set: Min = {X_val.min()}, Max = {X_val.max()}\")\nprint(f\"Our Test set: Min = {X_our_test.min()}, Max = {X_our_test.max()}\")\nprint(f\"Test set: Min = {X_test.min()}, Max = {X_test.max()}\")","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:25:04.042333Z","iopub.execute_input":"2024-12-13T00:25:04.042698Z","iopub.status.idle":"2024-12-13T00:25:04.275636Z","shell.execute_reply.started":"2024-12-13T00:25:04.042665Z","shell.execute_reply":"2024-12-13T00:25:04.274643Z"},"trusted":true,"id":"0qp3B4vj5xdr","outputId":"ed86cd21-5893-4612-8e5e-0d59a1761787","executionInfo":{"status":"ok","timestamp":1733671040881,"user_tz":-60,"elapsed":460,"user":{"displayName":"Jacopo Libero Tettamanti","userId":"12339511839544746744"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.savez_compressed(\"mars_datasets_superaug.npz\",\n                    X_train=X_train_new2,\n                    y_train=y_train_new2,\n                    X_val=X_val,\n                    y_val=y_val,\n                    X_our_test = X_our_test,\n                    y_our_test = y_our_test,\n                    X_test=X_test)\n\n\nFileLink(\"mars_datasets_superaug.npz\")","metadata":{"execution":{"iopub.status.busy":"2024-12-13T00:25:44.158802Z","iopub.execute_input":"2024-12-13T00:25:44.159209Z","iopub.status.idle":"2024-12-13T00:26:50.027594Z","shell.execute_reply.started":"2024-12-13T00:25:44.159175Z","shell.execute_reply":"2024-12-13T00:26:50.026698Z"},"trusted":true,"id":"QdtvWlXH5xdr","outputId":"873bdfb8-0722-4a6e-808d-aacedadf3e2a"},"outputs":[],"execution_count":null}]}